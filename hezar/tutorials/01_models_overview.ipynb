{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/hezarai/notebooks/blob/main/hezar/01_models_overview.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "In Hezar, models are the typical PyTorch modules with some extra features for loading, saving, exporting, etc.\n",
    "Let's dive into some of the most important ones!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Models Basics\n",
    "### Building Models\n",
    "Like any other package, you can import any model from `hezar.models` that you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aryan/Applications/miniconda3/envs/main/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from hezar.models import BertLM, BertLMConfig\n",
    "\n",
    "bert = BertLM(BertLMConfig())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also configure the architecture by changing the properties in a model's config like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BertLMConfig(num_hidden_layers=8, num_attention_heads=8)\n",
    "bert = BertLM(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Every model in Hezar, can be pushed to or downloaded from the Hub.\n",
    "\n",
    "### Loading pre-trained models\n",
    "Loading a model from Hub is as easy as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hezar.models import Model\n",
    "\n",
    "bert = Model.load(\"hezarai/bert-base-fa\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `load` methods takes the following steps to build the model:\n",
    "\n",
    "1. Load the config file `model_config.yaml` and figure out the model's class using the `name` config parameter. (`bert_lm` in this snippet)\n",
    "2. Build the model with random weights from the corresponding class. (`BertLM` in this snippet)\n",
    "3. Download the weights file (`model.pt`) and load the state dict into to the model.\n",
    "4. If the path contains any preprocessor, the preprocessor (`WordPieceTokenizer` in this snippet) will be loaded too.\n",
    "(You can disable loading preprocessors by setting `Model.load(path, load_preprocessor=False)`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Inference & Prediction\n",
    "Now that you have loaded a model along with its preprocessors, feature extractors, etc. you can perform an end-to-end\n",
    "inference in a single line of code using `Model.predict` method.\n",
    "\n",
    "A sequence labeling example would be like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS: [[{'token': 'شرکت', 'label': 'Ne'}, {'token': 'هوش', 'label': 'Ne'}, {'token': 'مصنوعی', 'label': 'AJe'}, {'token': 'هزار', 'label': 'NUM'}]]\n"
     ]
    }
   ],
   "source": [
    "from hezar.models import Model\n",
    "\n",
    "pos_model = Model.load(\"hezarai/bert-fa-pos-lscp-500k\")  # Part-of-speech\n",
    "inputs = [\"شرکت هوش مصنوعی هزار\"]\n",
    "pos_outputs = pos_model.predict(inputs)\n",
    "print(f\"POS: {pos_outputs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Saving Models\n",
    "You can save any model along with its config and preprocessor and other files on disk like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hezar.models import RobertaLM, RobertaLMConfig\n",
    "\n",
    "roberta = RobertaLM(RobertaLMConfig(vocab_size=60000))\n",
    "roberta.save(\"my-roberta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Pushing to the Hub\n",
    "Every model can be pushed to the Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model.pt:   1%|          | 4.55M/473M [00:19<09:47, 798kB/s]"
     ]
    }
   ],
   "source": [
    "from hezar.models import RobertaTextClassification, RobertaTextClassificationConfig\n",
    "\n",
    "roberta = RobertaTextClassification(RobertaTextClassificationConfig(num_labels=2))\n",
    "roberta.push_to_hub(\"arxyzan/roberta-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Custom Models\n",
    "Every Hezar model is a subclass of the base model class `Model` and the `Model` itself is a subclass of PyTorch `nn.Module`\n",
    "with some extra features. So if you're familiar with PyTorch, this should feel like home!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### A Sample Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from hezar.models import Model, ModelConfig, register_model\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PerceptronConfig(ModelConfig):\n",
    "    name = \"perceptron\"\n",
    "    input_shape: int = 4\n",
    "    output_shape: int = 2\n",
    "\n",
    "\n",
    "@register_model(\"perceptron\", config_class=PerceptronConfig)\n",
    "class Perceptron(Model):\n",
    "    \"\"\"\n",
    "    A simple single layer network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config, **kwargs):\n",
    "        super().__init__(config, **kwargs)\n",
    "        self.nn = nn.Linear(\n",
    "            in_features=self.config.input_shape,\n",
    "            out_features=self.config.output_shape,\n",
    "        )\n",
    "\n",
    "    def preprocess(self, raw_inputs):\n",
    "        inputs_tensor = Tensor(raw_inputs)\n",
    "        return inputs_tensor\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x.reshape(1, -1)\n",
    "        x = self.nn(x)\n",
    "        return x\n",
    "\n",
    "    def post_process(self, model_outputs: torch.Tensor):\n",
    "        return model_outputs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only point here is that you have to pass a `ModelConfig` to your model and read everything from the config and the\n",
    "rest is just typical PyTorch stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5652378  0.7015635]]\n"
     ]
    }
   ],
   "source": [
    "model = Perceptron(PerceptronConfig())\n",
    "inputs = [1, 2, 3, 4]\n",
    "outputs = model.predict(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a Hezar compatible model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hezar (INFO): Uploaded: `PerceptronConfig()` --> `arxyzan/perceptron/model_config.yaml`\n",
      "model.pt: 100%|██████████| 1.55k/1.55k [00:00<00:00, 4.15kB/s]\n",
      "Hezar (INFO): Uploaded: `Perceptron(name=perceptron)` --> `arxyzan/perceptron/model.pt`\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my-perceptron\")\n",
    "model.push_to_hub(\"arxyzan/perceptron\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To learn more about the internals of the models in Hezar take a look at [the models in-depth guide](../guide/models_advanced.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
